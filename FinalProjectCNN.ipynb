{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from random import shuffle\n",
    "from math import floor\n",
    "from cv2 import cvtColor, COLOR_BGR2GRAY\n",
    "import numpy as np\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "def CNN(images, labels, dimension, LR, target):\n",
    "\n",
    "    MODEL_NAME = 'testing-{}-{}.model'.format(LR, '6conv-basic')\n",
    "    \n",
    "    #one-hot encode the labels of the images [b,c,g,h,m]\n",
    "    encoded_class = list()\n",
    "    if target == 'Black Spot':\n",
    "        for each in labels:\n",
    "            if each == 'Black Spot':\n",
    "                encoded_class.append([1,0])\n",
    "            else:\n",
    "                encoded_class.append([0,1])\n",
    "    elif target == 'Canker':\n",
    "        for each in labels:\n",
    "            if each == 'Canker':\n",
    "                encoded_class.append([1,0])\n",
    "            else:\n",
    "                encoded_class.append([0,1])\n",
    "    elif target == 'Greening':\n",
    "        for each in labels:\n",
    "            if each == 'Greening':\n",
    "                encoded_class.append([1,0])\n",
    "            else:\n",
    "                encoded_class.append([0,1])\n",
    "    else:\n",
    "        for each in labels:\n",
    "            if each == 'Healthy':\n",
    "                encoded_class.append([1,0])\n",
    "            else:\n",
    "                encoded_class.append([0,1])\n",
    "\n",
    "    #convert images to grayscale to simplify problem\n",
    "    for index in range(len(images)):\n",
    "        #print(len(images[index][0][0]))\n",
    "        images[index] = cvtColor(images[index], COLOR_BGR2GRAY)\n",
    "   \n",
    "    #combine labels and images into one list and shuffle\n",
    "    data = list()\n",
    "    for index in range(len(images)):\n",
    "        data.append([np.array(images[index]),np.array(encoded_class[index])])\n",
    "    shuffle(data)\n",
    "    \n",
    "    train_data = data[:550]\n",
    "    test_data = data[550:]\n",
    "    \n",
    "    for index in range(len(test_data)):\n",
    "        test_data[index][1] = index\n",
    "\n",
    "\n",
    "    #create layers of neural network\n",
    "    net = input_data(shape =[None, dimension, dimension, 1], name ='input')\n",
    "    \n",
    "    net = conv_2d(net, 32, 5, activation ='relu')\n",
    "    net = max_pool_2d(net, 5)\n",
    "  \n",
    "    net = conv_2d(net, 64, 5, activation ='relu')\n",
    "    net = max_pool_2d(net, 5)\n",
    "  \n",
    "    net = conv_2d(net, 128, 5, activation ='relu')\n",
    "    net = max_pool_2d(net, 5)\n",
    "  \n",
    "    net = conv_2d(net, 64, 5, activation ='relu')\n",
    "    net = max_pool_2d(net, 5)\n",
    "\n",
    "    net = conv_2d(net, 32, 5, activation ='relu')\n",
    "    net = max_pool_2d(net, 5)\n",
    "  \n",
    "    net = fully_connected(net, 1024, activation ='relu')\n",
    "    net = dropout(net, 0.8)\n",
    "  \n",
    "    net = fully_connected(net, 2, activation ='softmax')\n",
    "    net = regression(net, learning_rate = LR, loss ='categorical_crossentropy', name ='targets')\n",
    "  \n",
    "    model = tflearn.DNN(net, tensorboard_dir ='log')\n",
    "    \n",
    "\n",
    "    # Splitting the testing data and training data\n",
    "    size = len(train_data)\n",
    "    split = floor(size*.8)\n",
    "    train = train_data[:split]\n",
    "    test = train_data[split:]\n",
    "    \n",
    "    # X-Features & Y-Labels\n",
    "    X = np.array([i[0] for i in train]).reshape(-1, dimension, dimension, 1)\n",
    "    Y = [i[1] for i in train]\n",
    "    test_x = np.array([i[0] for i in test]).reshape(-1, dimension, dimension, 1)\n",
    "    test_y = [i[1] for i in test]\n",
    "    \n",
    "    \n",
    "\n",
    "    # epoch = 5 taken\n",
    "    model.fit({'input': X}, {'targets': Y}, n_epoch = 5, \n",
    "    validation_set =({'input': test_x}, {'targets': test_y}), \n",
    "    snapshot_step = 500, show_metric = True, run_id = MODEL_NAME)\n",
    "    model.save(MODEL_NAME, tensorboard_dir ='log') \n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    # if you need to create the data:\n",
    "    # test_data = process_test_data()\n",
    "    # if you already have some saved:\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    for num, data in enumerate(test_data[:20]):\n",
    "      \n",
    "        img_num = data[1]\n",
    "        img_data = data[0]\n",
    "      \n",
    "        y = fig.add_subplot(4, 5, num + 1)\n",
    "        orig = img_data\n",
    "        data = img_data.reshape(dimension, dimension, 1)\n",
    "  \n",
    "        # model_out = model.predict([data])[0]\n",
    "        model_out = model.predict([data])[0]\n",
    "\n",
    "        if np.argmax(model_out) == 1: str_label ='Dog'\n",
    "        else: str_label ='Cat'\n",
    "          \n",
    "        y.imshow(orig, cmap ='gray')\n",
    "        plt.title(str_label)\n",
    "        y.axes.get_xaxis().set_visible(False)\n",
    "        y.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_spot = list()\n",
    "canker = list()\n",
    "greening = list()\n",
    "healthy = list()\n",
    "melanose = list()\n",
    "\n",
    "master_images = list() # compiled after resizing to contain images from all sets\n",
    "master_colors = list() # same as master images but each pixel is a string name for its color instead of a BGR component list\n",
    "master_file_names = list() # contains the names of the files in their appropriate order\n",
    "true_class = list() # a list of the true classifications of each image\n",
    "\n",
    "dimension = 8 # lowered for quicker testing \n",
    "LR = 1e-3 #learning rate for CNN\n",
    "\n",
    "black_spot, canker, greening, healthy, melanose = Resize_Images(dimension) # Resize images and set each of them to be compatible with OpenCV\n",
    "#print(black_spot[0])\n",
    "# Get the average representation of each of our identifier colors from the datasets, output is a list representing the average\n",
    "# presence of that color for the entire class represented by the list. This is in the form of [ green, brown, yellow ]. It also returns\n",
    "# a list of each image where all the pixels have been converted to their color names\n",
    "black_spot_color_averages, black_spot_pixels_as_color = BGR_Calculation(black_spot, dimension)\n",
    "canker_color_averages, canker_pixels_as_color = BGR_Calculation(canker, dimension)\n",
    "greening_color_averages, greening_pixels_as_color = BGR_Calculation(greening, dimension)\n",
    "healthy_color_averages, healthy_pixels_as_color = BGR_Calculation(healthy, dimension)\n",
    "melanose_color_averages, melanose_pixels_as_color = BGR_Calculation(melanose, dimension)\n",
    "\n",
    "# Combine lists to make a master of the previous datasets in order to split into training and testing data.\n",
    "Combine_Lists()\n",
    "\n",
    "#print(master_images[0])\n",
    "test = CNN(master_images, true_class, dimension, LR, 'Healthy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('finalProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96cb705b0ad2cc6e320110de264fb4379ed9cdb000cbd57a99aa99228735d864"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
