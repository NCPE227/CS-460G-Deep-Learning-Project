{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors:\n",
    "\n",
    "# Description: Use deep learning principles on a dataset of your choosing. We chose a dataset of citrus leaves with afflictions,\n",
    "# as well as healthy leaves for comparison. We will be using these images to predict which conditions (greening, black spot, canker, healthy)\n",
    "# the leaf appears to be. Following that, we will evaluate the performance of our algorithm implementation in order to provide metrics by which\n",
    "# out project may be judged and improved.\n",
    "\n",
    "# Dataset is available from the following link:\n",
    "# https://www.tensorflow.org/datasets/catalog/citrus_leaves\n",
    "\n",
    "import glob # used to get a list of all the files in a folder\n",
    "from cv2 import imread, resize, IMREAD_UNCHANGED # select the tools we need process our images\n",
    "\n",
    "# Lists to use for the output of the temporarily resized images\n",
    "black_spot = list()\n",
    "canker = list()\n",
    "greening = list()\n",
    "healthy = list()\n",
    "melanose = list()\n",
    "\n",
    "master_images = list() # compiled after resizing to contain images from all sets\n",
    "master_colors = list() # same as master images but each pixel is a string name for its color instead of a BGR component list\n",
    "master_file_names = list() # contains the names of the files in their appropriate order\n",
    "true_class = list() # a list of the true classifications of each image\n",
    "\n",
    "true_class_black_spot = list()\n",
    "true_class_canker = list()\n",
    "true_class_greening = list()\n",
    "true_class_healthy = list()\n",
    "true_class_melanose = list()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# When this function is run, it resizes all 5 image sets to a given square aspect ratio, doesn't write the images, but keeps them in a list\n",
    "def Resize_Images(new_dimension):\n",
    "    images = list()\n",
    "    black_spot_resized = list()\n",
    "    canker_resized = list()\n",
    "    greening_resized = list()\n",
    "    healthy_resized = list()\n",
    "    melanose_resized = list()\n",
    "\n",
    "    dimension_size = (new_dimension, new_dimension) #set dimensions_size to be new_dimension pixels in height and width\n",
    "\n",
    "    #Get a list of the images in the given directory, then for each of those images, make a temporary file of that image with a new aspect ratio\n",
    "    images = glob.glob('./Citrus/Leaves/Black spot/*.png') #get the names files in the Black spot folder as a list\n",
    "\n",
    "    for image in images: #resize black spot images\n",
    "        image = image.replace('\\\\', '/')\n",
    "        source_image = imread(image, IMREAD_UNCHANGED) #set the source image\n",
    "        #print('Original Dimension: ', source_image.shape)\n",
    "        resized_image = resize(source_image, dimension_size) #change the dimensions of the image\n",
    "        #print('New Dimension: ', source_image.shape)\n",
    "        black_spot_resized.append(resized_image) #add the new temporary images to a list\n",
    "    #print('Size of Black Spot List: ', len(black_spot_resized))\n",
    "\n",
    "    #Get a list of the images in the given directory, then for each of those images, make a temporary file of that image with a new aspect ratio\n",
    "    images = glob.glob('./Citrus/Leaves/canker/*.png') #get the names files in the Black spot folder as a list\n",
    " \n",
    "    for image in images: #resize canker images\n",
    "        image = image.replace('\\\\', '/')\n",
    "        source_image = imread(image, IMREAD_UNCHANGED) #set the source image\n",
    "        #print(source_image)\n",
    "        #print('Original Dimension: ', source_image.shape)\n",
    "        resized_image = resize(source_image, dimension_size) #change the dimensions of the image\n",
    "        #print('New Dimension: ', resized_image.shape)\n",
    "        canker_resized.append(resized_image) #add the new temporary images to a list\n",
    "    #print('Size of canker List: ', len(black_spot_resized))\n",
    "\n",
    "    #Get a list of the images in the given directory, then for each of those images, make a temporary file of that image with a new aspect ratio\n",
    "    images = glob.glob('./Citrus/Leaves/greening/*.png') #get the names files in the Black spot folder as a list\n",
    "\n",
    "    for image in images: #resize greening images\n",
    "        image = image.replace('\\\\', '/')\n",
    "        source_image = imread(image, IMREAD_UNCHANGED) #set the source image\n",
    "        #print('Original Dimension: ', source_image.shape)\n",
    "        resized_image = resize(source_image, dimension_size) #change the dimensions of the image\n",
    "        greening_resized.append(resized_image) #add the new temporary images to a list\n",
    "\n",
    "    #Get a list of the images in the given directory, then for each of those images, make a temporary file of that image with a new aspect ratio\n",
    "    images = glob.glob('./Citrus/Leaves/healthy/*.png') #get the names files in the Black spot folder as a list\n",
    "\n",
    "    for image in images: #resize healthy images\n",
    "        image = image.replace('\\\\', '/')\n",
    "        source_image = imread(image, IMREAD_UNCHANGED) #set the source image\n",
    "        #print('Original Dimension: ', source_image.shape)\n",
    "        resized_image = resize(source_image, dimension_size) #change the dimensions of the image\n",
    "        healthy_resized.append(resized_image) #add the new temporary images to a list\n",
    "\n",
    "    #Get a list of the images in the given directory, then for each of those images, make a temporary file of that image with a new aspect ratio\n",
    "    images = glob.glob('./Citrus/Leaves/Melanose/*.png') #get the names files in the Black spot folder as a list\n",
    "\n",
    "    for image in images: #resize melanose images\n",
    "        image = image.replace('\\\\', '/')\n",
    "        source_image = imread(image, IMREAD_UNCHANGED) #set the source image\n",
    "        #print('Original Dimension: ', source_image.shape)\n",
    "        resized_image = resize(source_image, dimension_size) #change the dimensions of the image\n",
    "        melanose_resized.append(resized_image) #add the new temporary images to a list\n",
    "\n",
    "    return black_spot_resized, canker_resized, greening_resized, healthy_resized, melanose_resized #return all the lists\n",
    "\n",
    "# OpenCV (cv2) uses BGR rather than RGB orientation\n",
    "# Use the BGR values of the pixels in our images post-scaling to determine the color of each pixel, then get a ratio of the colors of each image\n",
    "# which we will use as our basis for predicting which condition the image depicts.\n",
    "#\n",
    "# Returns a list of the average occurence of colors per each condition. We will use this for predictions\n",
    "def BGR_Calculation(image_list, new_dimension):\n",
    "    x_dimension = new_dimension\n",
    "    y_dimension = new_dimension\n",
    "    pixel_colors = list() # temporary list for each pixel\n",
    "    image_colors = list() # list of lists, each sublist contains the color predictions for the pixels of the given image\n",
    "    color_name = list() # list of color names that correspond to each pixel of each image\n",
    "\n",
    "    # For each image in the image_list, we are going to get the BGR values of each pixel in the image\n",
    "    for image in image_list:\n",
    "        pixel_colors = [] #set the temp list back to empty\n",
    "\n",
    "        # Calculate the BGR values for each pixel in the image\n",
    "        for pixel_y in range(y_dimension):\n",
    "            for pixel_x in range(x_dimension):\n",
    "                pixel_colors.append(image[pixel_x, pixel_y].tolist())\n",
    "        \n",
    "        image_colors.append(pixel_colors) # add the list of arrays to a master list where each of these lists is an image\n",
    "    \n",
    "    # For each pixel in each image in image_colors, determine it's color by the BGR ratio\n",
    "    for image in image_colors:\n",
    "        temp_color_name = list() # use this to create a list for an individual image, then add the list to the color_name list\n",
    "        for pixel in image:\n",
    "            if ((pixel[2] > pixel[0]) & (pixel[2] > pixel[1])): # detect a brown pixel\n",
    "                temp_color_name.append('brown')\n",
    "            elif ((pixel[0] > pixel[1]) & (pixel[0] > pixel[2])): # detect the background of an image\n",
    "                temp_color_name.append('background')\n",
    "            elif ((pixel[1] > pixel[0]) & (pixel[1] > pixel[2])): # detect a green pixel\n",
    "                temp_color_name.append('green')\n",
    "            elif ((pixel[0] > pixel[2]) & (pixel[1] > pixel[2])): # detect a yellow pixel\n",
    "                temp_color_name.append('yellow')\n",
    "        color_name.append(temp_color_name) # add the temp list to this so we have a list of lists which corresponds with the pixels in the image_colors list of lists\n",
    "    #print(color_name)\n",
    "\n",
    "    # Count the appearances of each of the leaf colors, ignoring the background colors\n",
    "    green, brown, yellow = 0, 0, 0 # color counting variables\n",
    "    average_green, average_yellow, average_brown = 0, 0, 0\n",
    "    for image in color_name:\n",
    "        for color in image:\n",
    "            #print(color)\n",
    "            if color == 'green':\n",
    "                green += 1\n",
    "            elif color == 'brown':\n",
    "                brown += 1\n",
    "            elif color == 'yellow':\n",
    "                yellow +=1\n",
    "        # Add the counted values for this image to the average variable\n",
    "        average_green += green\n",
    "        average_brown += brown\n",
    "        average_yellow += yellow\n",
    "    \n",
    "    # Divide each category by the number of items in color_name to get an average color value for each class\n",
    "    average_green = average_green / len(color_name)\n",
    "    average_brown = average_brown / len(color_name)\n",
    "    average_yellow = average_yellow / len(color_name)\n",
    "\n",
    "    average_colors = [average_green, average_brown, average_yellow] # create a variable to store the averages to be returned\n",
    "            \n",
    "    return average_colors, color_name\n",
    "\n",
    "# This function creates the master list of all the datasets and a list of their true classifications\n",
    "def Combine_Lists():\n",
    "    for each in range(len(black_spot)):\n",
    "        master_images.append(black_spot[each])\n",
    "        master_colors.append(black_spot_pixels_as_color[each])\n",
    "        master_file_names.append(f'b{each}.png')\n",
    "        true_class.append('Black Spot')\n",
    "        true_class_black_spot.append('Black Spot')\n",
    "    \n",
    "    for each in range(len(canker)):\n",
    "        master_images.append(canker[each])\n",
    "        master_colors.append(canker_pixels_as_color[each])\n",
    "        master_file_names.append(f'c{each}.png')\n",
    "        true_class.append('Canker')\n",
    "        true_class_canker.append('Canker')\n",
    "    \n",
    "    for each in range(len(greening)):\n",
    "        master_images.append(greening[each])\n",
    "        master_colors.append(greening_pixels_as_color[each])\n",
    "        master_file_names.append(f'g{each}.png')\n",
    "        true_class.append('Greening')\n",
    "        true_class_greening.append('Greening')\n",
    "\n",
    "    \n",
    "    for each in range(len(healthy)):\n",
    "        master_images.append(healthy[each])\n",
    "        master_colors.append(healthy_pixels_as_color[each])\n",
    "        master_file_names.append(f'h{each}.png')\n",
    "        true_class.append('Healthy')\n",
    "    \n",
    "    for each in range(len(melanose)):\n",
    "        master_images.append(melanose[each])\n",
    "        master_colors.append(melanose_pixels_as_color[each])\n",
    "        master_file_names.append(f'm{each}.png')\n",
    "        true_class.append('Melanose')\n",
    "        true_class_melanose.append('Melanose')\n",
    "\n",
    "\n",
    "dimension = 4 # lowered for quicker testing \n",
    "\n",
    "black_spot, canker, greening, healthy, melanose = Resize_Images(dimension) # Resize images and set each of them to be compatible with OpenCV\n",
    "\n",
    "# Get the average representation of each of our identifier colors from the datasets, output is a list representing the average\n",
    "# presence of that color for the entire class represented by the list. This is in the form of [ green, brown, yellow ]. It also returns\n",
    "# a list of each image where all the pixels have been converted to their color names\n",
    "black_spot_color_averages, black_spot_pixels_as_color = BGR_Calculation(black_spot, dimension)\n",
    "canker_color_averages, canker_pixels_as_color = BGR_Calculation(canker, dimension)\n",
    "greening_color_averages, greening_pixels_as_color = BGR_Calculation(greening, dimension)\n",
    "healthy_color_averages, healthy_pixels_as_color = BGR_Calculation(healthy, dimension)\n",
    "melanose_color_averages, melanose_pixels_as_color = BGR_Calculation(melanose, dimension)\n",
    "\n",
    "# Combine lists to make a master of the previous datasets in order to split into training and testing data.\n",
    "Combine_Lists()\n",
    "#print(black_spot[0])\n",
    "\n",
    "#Simply for proof of run, this makes it take a LONG TIME, leave commented out for real runs.\n",
    "#print(master_images[0])\n",
    "#print()\n",
    "#print(master_images[1])\n",
    "#print(master_colors[0])\n",
    "#print(len(master_colors[0]))\n",
    "\n",
    "'''#Testing using a single image\n",
    "source_image = imread('./Citrus/Leaves/Black spot/b0.png', IMREAD_UNCHANGED) #set the source image\n",
    "#print('Original Dimension: ', source_image.shape)\n",
    "resized_image = resize(source_image, (256, 256)) #change the dimensions of the image\n",
    "#print('New Dimension: ', source_image.shape)\n",
    "black_spot.append(resized_image) #add the new temporary images to a list\n",
    "#print('Size of Black Spot List: ', len(black_spot_resized))\n",
    "average_occurences = BGR_Calculation(black_spot, 256)\n",
    "print('Black Spot Average: ', average_occurences)\n",
    "\n",
    "source_image = imread('./Citrus/Leaves/canker/c0.png', IMREAD_UNCHANGED) #set the source image\n",
    "#print('Original Dimension: ', source_image.shape)\n",
    "resized_image = resize(source_image, (256, 256)) #change the dimensions of the image\n",
    "#print('New Dimension: ', source_image.shape)\n",
    "canker.append(resized_image) #add the new temporary images to a list\n",
    "#print('Size of Black Spot List: ', len(black_spot_resized))\n",
    "average_occurences = BGR_Calculation(canker, 256)\n",
    "print('Canker Average: ', average_occurences)\n",
    "\n",
    "source_image = imread('./Citrus/Leaves/greening/g0.png', IMREAD_UNCHANGED) #set the source image\n",
    "#print('Original Dimension: ', source_image.shape)\n",
    "resized_image = resize(source_image, (256, 256)) #change the dimensions of the image\n",
    "#print('New Dimension: ', source_image.shape)\n",
    "greening.append(resized_image) #add the new temporary images to a list\n",
    "#print('Size of Black Spot List: ', len(black_spot_resized))\n",
    "average_occurences = BGR_Calculation(greening, 256)\n",
    "print('Greening Average: ', average_occurences)\n",
    "\n",
    "source_image = imread('./Citrus/Leaves/healthy/h0.png', IMREAD_UNCHANGED) #set the source image\n",
    "#print('Original Dimension: ', source_image.shape)\n",
    "resized_image = resize(source_image, (256, 256)) #change the dimensions of the image\n",
    "#print('New Dimension: ', source_image.shape)\n",
    "healthy.append(resized_image) #add the new temporary images to a list\n",
    "#print('Size of Black Spot List: ', len(black_spot_resized))\n",
    "average_occurences = BGR_Calculation(healthy, 256)\n",
    "print('Healthy Average: ', average_occurences)\n",
    "\n",
    "source_image = imread('./Citrus/Leaves/Melanose/m0.png', IMREAD_UNCHANGED) #set the source image\n",
    "#print('Original Dimension: ', source_image.shape)\n",
    "resized_image = resize(source_image, (256, 256)) #change the dimensions of the image\n",
    "#print('New Dimension: ', source_image.shape)\n",
    "melanose.append(resized_image) #add the new temporary images to a list\n",
    "#print('Size of Black Spot List: ', len(black_spot_resized))\n",
    "average_occurences = BGR_Calculation(melanose, 256)\n",
    "print('Melanose Average: ', average_occurences)'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from random import shuffle\n",
    "from math import floor\n",
    "from cv2 import cvtColor, COLOR_BGR2GRAY #COLOR_BGR2HSV \n",
    "import numpy as np\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "def CNN(images, labels, dimension, LR, target):\n",
    "\n",
    "    MODEL_NAME = 'testing-{}-{}.model'.format(LR, '6conv-basic')\n",
    "    \n",
    "    #one-hot encode the labels of the images [b,c,g,h,m]\n",
    "    encoded_class = list()\n",
    "    if target == 'Black Spot':\n",
    "        for each in labels:\n",
    "            if each == 'Black Spot':\n",
    "                encoded_class.append([1,0])\n",
    "            else:\n",
    "                encoded_class.append([0,1])\n",
    "    elif target == 'Canker':\n",
    "        for each in labels:\n",
    "            if each == 'Canker':\n",
    "                encoded_class.append([1,0])\n",
    "            else:\n",
    "                encoded_class.append([0,1])\n",
    "    elif target == 'Greening':\n",
    "        for each in labels:\n",
    "            if each == 'Greening':\n",
    "                encoded_class.append([1,0])\n",
    "            else:\n",
    "                encoded_class.append([0,1])\n",
    "    else:\n",
    "        for each in labels:\n",
    "            if each == 'Healthy':\n",
    "                encoded_class.append([1,0])\n",
    "            else:\n",
    "                encoded_class.append([0,1])\n",
    "\n",
    "    #convert images to grayscale to simplify problem\n",
    "    for index in range(len(images)):\n",
    "        #print(len(images[index][0][0]))\n",
    "        images[index] = cvtColor(images[index], COLOR_BGR2GRAY)\n",
    "   \n",
    "    #combine labels and images into one list and shuffle\n",
    "    data = list()\n",
    "    for index in range(len(images)):\n",
    "        data.append([np.array(images[index]),np.array(encoded_class[index])])\n",
    "    shuffle(data)\n",
    "    \n",
    "    train_data = data[:550]\n",
    "    test_data = data[550:]\n",
    "    \n",
    "    for index in range(len(test_data)):\n",
    "        test_data[index][1] = index\n",
    "\n",
    "\n",
    "    #create layers of neural network\n",
    "    net = input_data(shape =[None, dimension, dimension, 1], name ='input')\n",
    "    \n",
    "    net = conv_2d(net, 32, 5, activation ='relu')\n",
    "    net = max_pool_2d(net, 5)\n",
    "  \n",
    "    net = conv_2d(net, 64, 5, activation ='relu')\n",
    "    net = max_pool_2d(net, 5)\n",
    "  \n",
    "    net = conv_2d(net, 128, 5, activation ='relu')\n",
    "    net = max_pool_2d(net, 5)\n",
    "  \n",
    "    net = conv_2d(net, 64, 5, activation ='relu')\n",
    "    net = max_pool_2d(net, 5)\n",
    "\n",
    "    net = conv_2d(net, 32, 5, activation ='relu')\n",
    "    net = max_pool_2d(net, 5)\n",
    "  \n",
    "    net = fully_connected(net, 1024, activation ='relu')\n",
    "    net = dropout(net, 0.8)\n",
    "  \n",
    "    net = fully_connected(net, 2, activation ='softmax')\n",
    "    net = regression(net, learning_rate = LR, loss ='categorical_crossentropy', name ='targets')\n",
    "  \n",
    "    model = tflearn.DNN(net, tensorboard_dir ='log')\n",
    "    \n",
    "\n",
    "    # Splitting the testing data and training data\n",
    "    size = len(train_data)\n",
    "    split = floor(size*.8)\n",
    "    train = train_data[:split]\n",
    "    test = train_data[split:]\n",
    "    \n",
    "    # X-Features & Y-Labels\n",
    "    X = np.array([i[0] for i in train]).reshape(-1, dimension, dimension, 1)\n",
    "    Y = [i[1] for i in train]\n",
    "    test_x = np.array([i[0] for i in test]).reshape(-1, dimension, dimension, 1)\n",
    "    test_y = [i[1] for i in test]\n",
    "    \n",
    "    \n",
    "\n",
    "    # epoch = 5 taken\n",
    "    model.fit({'input': X}, {'targets': Y}, n_epoch = 5, \n",
    "    validation_set =({'input': test_x}, {'targets': test_y}), \n",
    "    snapshot_step = 500, show_metric = True, run_id = MODEL_NAME)\n",
    "    #model.save(MODEL_NAME, tensorboard_dir ='log') \n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    # if you need to create the data:\n",
    "    # test_data = process_test_data()\n",
    "    # if you already have some saved:\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    for num, data in enumerate(test_data[:20]):\n",
    "      \n",
    "        img_num = data[1]\n",
    "        img_data = data[0]\n",
    "      \n",
    "        y = fig.add_subplot(4, 5, num + 1)\n",
    "        orig = img_data\n",
    "        data = img_data.reshape(dimension, dimension, 1)\n",
    "  \n",
    "        # model_out = model.predict([data])[0]\n",
    "        model_out = model.predict([data])[0]\n",
    "\n",
    "        if np.argmax(model_out) == 1: str_label ='Healthy'\n",
    "        else: str_label ='Blemish'\n",
    "          \n",
    "        y.imshow(orig, cmap ='gray')\n",
    "        plt.title(str_label)\n",
    "        y.axes.get_xaxis().set_visible(False)\n",
    "        y.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_spot = list()\n",
    "canker = list()\n",
    "greening = list()\n",
    "healthy = list()\n",
    "melanose = list()\n",
    "\n",
    "master_images = list() # compiled after resizing to contain images from all sets\n",
    "master_colors = list() # same as master images but each pixel is a string name for its color instead of a BGR component list\n",
    "master_file_names = list() # contains the names of the files in their appropriate order\n",
    "true_class = list() # a list of the true classifications of each image\n",
    "\n",
    "dimension = 8 # lowered for quicker testing \n",
    "LR = 1e-3 #learning rate for CNN\n",
    "\n",
    "black_spot, canker, greening, healthy, melanose = Resize_Images(dimension) # Resize images and set each of them to be compatible with OpenCV\n",
    "#print(black_spot[0])\n",
    "# Get the average representation of each of our identifier colors from the datasets, output is a list representing the average\n",
    "# presence of that color for the entire class represented by the list. This is in the form of [ green, brown, yellow ]. It also returns\n",
    "# a list of each image where all the pixels have been converted to their color names\n",
    "black_spot_color_averages, black_spot_pixels_as_color = BGR_Calculation(black_spot, dimension)\n",
    "canker_color_averages, canker_pixels_as_color = BGR_Calculation(canker, dimension)\n",
    "greening_color_averages, greening_pixels_as_color = BGR_Calculation(greening, dimension)\n",
    "healthy_color_averages, healthy_pixels_as_color = BGR_Calculation(healthy, dimension)\n",
    "melanose_color_averages, melanose_pixels_as_color = BGR_Calculation(melanose, dimension)\n",
    "\n",
    "# Combine lists to make a master of the previous datasets in order to split into training and testing data.\n",
    "Combine_Lists()\n",
    "\n",
    "#print(master_images[0])\n",
    "#test = CNN(master_images, true_class, dimension, LR, 'Healthy')\n",
    "#test_black = CNN(black_spot, true_class_black_spot, dimension, LR, 'Healthy')\n",
    "#test_greening = CNN(greening, true_class, dimension, LR, 'Healthy')\n",
    "#test_canker = CNN(canker, true_class_canker, dimension, LR, 'Healthy')\n",
    "#test_melanose = CNN(melanose, true_class_melanose, dimension, LR, 'Healthy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = CNN(master_images, true_class, dimension, LR, 'Healthy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_black = CNN(black_spot, true_class_black_spot, dimension, LR, 'Healthy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_greening = CNN(greening, true_class, dimension, LR, 'Healthy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_canker = CNN(canker, true_class, dimension, LR, 'Healthy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_melanose = CNN(melanose, true_class_melanose, dimension, LR, 'Healthy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Dec  6 15:58:00 2022\n",
    "\n",
    "@author: Dallas Garriott\n",
    "Machine Learning Citrus Leaves Group Project - Metrics\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from math import sqrt\n",
    "import numpy\n",
    "from sklearn import metrics\n",
    "\n",
    "#confusion matrix = predicted vs actual... Accuracy = (true+ + true-)/totalsample\n",
    "actual = list()\n",
    "predictions = list()\n",
    "\n",
    "confusionmatrix = metrics.confusion_matrix(actual, predictions)\n",
    "\n",
    "display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusionmatrix, display_labels = [False, True])\n",
    "print(\"Confusion Matrix\")\n",
    "print(\"   FF FT\")\n",
    "print(confusionmatrix)\n",
    "print(\"   TF TT\")\n",
    "\n",
    "#accuracy=(number of correct predictions)/(total number of predictions made)\n",
    "print(\"Accuracy: %.3f\" % accuracy_score(actual, predictions))\n",
    "\n",
    "#Mean squared error = (1/N) * summation from j=1 to N (ysubj - ynaughtsubj)^2\n",
    "def mserror(actual,predictions):\n",
    "    sum_error = 0.000\n",
    "    for i in range(len(actual)):\n",
    "        predict_error = predictions[i]-actual[i]\n",
    "        sum_error += (predict_error ** 2)\n",
    "    smean_error = sum_error / float(len(actual))\n",
    "    return smean_error\n",
    "print(\"Mean squared error: %.3f\" % mserror(actual, predictions))\n",
    "print(\"Root mean squared error: %.3f\" % sqrt(mserror(actual,predictions)))\n",
    "\n",
    "\n",
    "#Mean absolute error = (1/N) * summation from j=1 to N (absolutevalue(ysubj-ynaughtj))\n",
    "def maerror(actual,predictions):\n",
    "    sum_error = 0.000\n",
    "    for i in range(len(actual)):\n",
    "        sum_error += abs(actual[i]-predictions[i])\n",
    "    amean_error = sum_error / float(len(actual))\n",
    "    return amean_error\n",
    "print(\"Mean absolute error: %.3f\" % maerror(actual,predictions))\n",
    "    \n",
    "\n",
    "#F1 Score = 2* (1/((1/precision)+(1/recall)))\n",
    "print(\"F1 Score Micro: %.3f\" % f1_score(actual, predictions, average= \"micro\"))\n",
    "print(\"F1 Score Macro: %.3f\" % f1_score(actual, predictions, average= \"macro\"))\n",
    "print(\"F1 Score Weighted: %.3f\" % f1_score(actual, predictions, average= \"weighted\"))\n",
    "\n",
    "\n",
    "#precision= true+/(true+ + false+); recall= true+/(true+ + false-)\n",
    "print(\"Precision Micro: %.3f\" % precision_score(actual, predictions, average= \"micro\"))\n",
    "print(\"Precision Macro: %.3f\" % precision_score(actual, predictions, average= \"macro\"))\n",
    "print(\"Precision Weighted: %.3f\" % precision_score(actual, predictions, average= \"weighted\"))\n",
    "\n",
    "print(\"Recall Micro: %.3f\" % recall_score(actual, predictions, average= \"micro\"))\n",
    "print(\"Recall Macro: %.3f\" % recall_score(actual, predictions, average= \"macro\"))\n",
    "print(\"Recall Weighted: %.3f\" % recall_score(actual, predictions, average= \"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mserror()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc5fd53eeaa017af79377ec66ea6e9db84fcc0b356e78745cc589cc461ec56e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
